{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "import openai\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "\n",
    "from llama_index.llms.cohere import Cohere\n",
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "\n",
    "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
    "from llama_index.core.query_engine import TransformQueryEngine, RetrieverQueryEngine\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, PromptTemplate, ServiceContext\n",
    "\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "from llama_index.core.postprocessor import LLMRerank\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'OPENAI_API_KEY'\n",
    "\n",
    "# Cohere\n",
    "API_KEY_COHERE = 'API_KEY_COHERE'\n",
    "# Antrophic\n",
    "API_KEY_ANTROPHIC = \"API_KEY_ANTROPHIC\"\n",
    "# Google\n",
    "API_KEY_GOOGLE = 'API_KEY_GOOGLE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_path = '../context_files'\n",
    "#documents = SimpleDirectoryReader(input_dir_path).load_data()\n",
    "\n",
    "loader = SimpleDirectoryReader(\n",
    "            input_dir = input_dir_path,\n",
    "            required_exts=[\".pdf\"],\n",
    "            recursive=True\n",
    "        )\n",
    "documents = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "# OpenAI - GPT 4\n",
    "llm = OpenAI(model=\"gpt-4o\")\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Antrophic - Claude 3 opus\n",
    "llm = Anthropic(model=\"claude-3-opus-20240229\", api_key=API_KEY_ANTROPHIC)\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Cohere - Command R+\n",
    "llm = Cohere(api_key=API_KEY_COHERE, model=\"command-r-plus\")\n",
    "embed_model = CohereEmbedding(cohere_api_key=API_KEY_COHERE, model_name=\"embed-english-v3.0\", input_type=\"search_query\",)\n",
    "\n",
    "# Google - Gemini 1.5\n",
    "llm = Gemini(api_key=API_KEY_GOOGLE, model=\"models/gemini-1.5-pro-latest\")\n",
    "embed_model = GeminiEmbedding(model_name=\"models/text-embedding-004\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm = llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_qa_template_str = (\n",
    "    \"\"\"  \n",
    "    You are an expert in Nuclear Medicine that is trusted around the world for your factual accuracy.\n",
    "    If the context isn't helpful, you can also answer the question on your pretrained knowledge\n",
    "\n",
    "    Some rules to follow:\n",
    "    1. Directly reference the given context according to Havard citation style in your answer. Do not include the path where the document is saved.\n",
    "    2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
    "    3. Focus on succinct answers that provide only the facts necessary, do not be verbose.\n",
    "    4. Answer the question in the language of the question (if the question is in German, answer in German. If the question is in English answer in English)\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    Given the context information and not prior knowledge, answer the query.\n",
    "    Query: {query_str}\n",
    "    Answer: \"\"\") \n",
    "text_qa_template = PromptTemplate(text_qa_template_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive RAG\n",
    "query_engine_naive = index.as_query_engine(llm = llm,\n",
    "                                           similarity_top_k=3,\n",
    "                                           text_qa_template=text_qa_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyDE\n",
    "hyde = HyDEQueryTransform(include_original=True)\n",
    "\n",
    "# LLM Rerank\n",
    "llm_rerank = LLMRerank(choice_batch_size=10, top_n=3)\n",
    "query_engine_llm_rerank = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    text_qa_template=text_qa_template,\n",
    "    node_postprocessors=[llm_rerank],\n",
    "    # embed_model=embed_model,\n",
    "    llm=llm\n",
    ")\n",
    "# HyDE + LLM Rerank\n",
    "query_engine_hyde_llm_rerank = TransformQueryEngine(query_engine_llm_rerank, hyde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_answers function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(dataframe, answer_list, context_list, llm):\n",
    "    for i in range(len(dataframe['Question'])):\n",
    "        print(dataframe['Question'][i])\n",
    "        user_prompt = dataframe['Question'][i]\n",
    "        \n",
    "        try:\n",
    "            response = query_engine_hyde_llm_rerank.query(user_prompt)\n",
    "        except:\n",
    "            pass\n",
    "        # Get the context from the Llama index\n",
    "        context = [x.text for x in response.source_nodes]\n",
    "\n",
    "        answer_list.append(response)\n",
    "        context_list.append(context)\n",
    "\n",
    "        dataframe.loc[i, 'LLM'] = llm\n",
    "\n",
    "        # adding advanced RAG to every questionId\n",
    "        question_id = dataframe.loc[i, 'QuestionId']\n",
    "        new_question_id = str(question_id) + ' advanced RAG'\n",
    "        \n",
    "\n",
    "        dataframe.loc[i, 'QuestionId'] = new_question_id\n",
    "\n",
    "        print(response)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antrophic Advanced RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_opus_context_advancedRAG_question_df = pd.read_csv(\"../Evaluation-Questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_answers = []\n",
    "claude_context = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_opus_context_advancedRAG_question_df['context'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answers(claude_opus_context_advancedRAG_question_df, claude_answers, claude_context, 'claude-3-opus-20240229 advanced RAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dataframe\n",
    "claude_opus_context_advancedRAG_question_df['answer'] = pd.DataFrame({'answers': claude_answers})\n",
    "claude_opus_context_advancedRAG_question_df['context'] = pd.DataFrame({'context': claude_context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './csv-advancedRAG/Claude-3-opus_context_advancedRAG_EvaluationQuestions.csv'\n",
    "claude_opus_context_advancedRAG_question_df.to_csv(filename, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohere Advanced RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_r_plus_context_advancedRAG_question_df = pd.read_csv(\"../Evaluation-Questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_answers = []\n",
    "command_context = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_r_plus_context_advancedRAG_question_df['context'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answers(command_r_plus_context_advancedRAG_question_df, command_answers, command_context, 'command-r-plus advanced RAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dataframe\n",
    "command_r_plus_context_advancedRAG_question_df['answer'] = pd.DataFrame({'answers': command_answers})\n",
    "command_r_plus_context_advancedRAG_question_df['context'] = pd.DataFrame({'context': command_context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './csv-advancedRAG/Command_r_plus_context_advancedRAG_EvaluationQuestions.csv'\n",
    "command_r_plus_context_advancedRAG_question_df.to_csv(filename, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Advanced RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_context_advancedRAG_question_df = pd.read_csv(\"../Evaluation-Questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_answers = []\n",
    "gpt_context = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_context_advancedRAG_question_df['context'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answers(gpt_4_context_advancedRAG_question_df, gpt_answers, gpt_context, 'gpt-4-turbo advanced RAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dataframe\n",
    "gpt_4_context_advancedRAG_question_df['answer'] = pd.DataFrame({'answers': gpt_answers})\n",
    "gpt_4_context_advancedRAG_question_df['context'] = pd.DataFrame({'context': gpt_context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './csv-advancedRAG/GPT_4_context_advancedRAG_EvaluationQuestions.csv'\n",
    "gpt_4_context_advancedRAG_question_df.to_csv(filename, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_context_advancedRAG_question_df = pd.read_csv(\"../Evaluation-Questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpto_answers = []\n",
    "gpto_context = []\n",
    "gpt_4o_context_advancedRAG_question_df['context'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answers(gpt_4o_context_advancedRAG_question_df, gpto_answers, gpto_context, 'gpt-4o advanced RAG')\n",
    "# update dataframe\n",
    "gpt_4o_context_advancedRAG_question_df['answer'] = pd.DataFrame({'answers': gpto_answers})\n",
    "gpt_4o_context_advancedRAG_question_df['context'] = pd.DataFrame({'context': gpto_context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './csv-advancedRAG/GPT_4o_context_advancedRAG_EvaluationQuestions.csv'\n",
    "gpt_4o_context_advancedRAG_question_df.to_csv(filename, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini Advanced RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_context_advancedRAG_question_df = pd.read_csv(\"../Evaluation-Questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_answers = []\n",
    "gemini_context = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_context_advancedRAG_question_df['context'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answers(gemini_context_advancedRAG_question_df, gemini_answers, gemini_context, 'gemini-1.5-pro-latest advanced RAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dataframe\n",
    "gemini_context_advancedRAG_question_df['answer'] = pd.DataFrame({'answers': gemini_answers})\n",
    "gemini_context_advancedRAG_question_df['context'] = pd.DataFrame({'context': gemini_context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './csv-advancedRAG/Gemini-1-5_context_advancedRAG_EvaluationQuestions.csv'\n",
    "gemini_context_advancedRAG_question_df.to_csv(filename, sep=',', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
