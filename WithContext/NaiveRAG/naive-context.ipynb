{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "import openai\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "\n",
    "from llama_index.llms.cohere import Cohere\n",
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "\n",
    "from llama_index.llms.mistralai import MistralAI\n",
    "from llama_index.embeddings.mistralai import MistralAIEmbedding\n",
    "\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, PromptTemplate, ServiceContext\n",
    "\n",
    "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
    "from llama_index.core.query_engine import TransformQueryEngine, RetrieverQueryEngine\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.postprocessor import LLMRerank\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'OPENAI_API_KEY'\n",
    "\n",
    "# Cohere\n",
    "API_KEY_COHERE = 'API_KEY_COHERE'\n",
    "# Antrophic\n",
    "API_KEY_ANTROPHIC = \"API_KEY_ANTROPHIC\"\n",
    "# Google\n",
    "API_KEY_GOOGLE = 'API_KEY_GOOGLE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_path = '../context_files'\n",
    "\n",
    "loader = SimpleDirectoryReader(\n",
    "            input_dir = input_dir_path,\n",
    "            required_exts=[\".pdf\"],\n",
    "            recursive=True\n",
    "        )\n",
    "documents = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Context\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# OpenAI - GPT 4\n",
    "llm = OpenAI(model=\"gpt-4-turbo\")\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "\n",
    "# OpenAI - GPT 4o\n",
    "llm = OpenAI(model=\"gpt-4o\")\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Antrophic - Claude 3 opus\n",
    "llm = Anthropic(model=\"claude-3-opus-20240229\", api_key=API_KEY_ANTROPHIC)\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Cohere - Command R+\n",
    "llm = Cohere(api_key=API_KEY_COHERE, model=\"command-r-plus\")\n",
    "embed_model = CohereEmbedding(cohere_api_key=API_KEY_COHERE, model_name=\"embed-english-v3.0\", input_type=\"search_query\",)\n",
    "\n",
    "# Google - Gemini 1.5\n",
    "llm = Gemini(api_key=API_KEY_GOOGLE, model=\"models/gemini-1.5-pro-latest\")\n",
    "embed_model = GeminiEmbedding(model_name=\"models/text-embedding-004\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VectorStore\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_qa_template_str = (\n",
    "    \"\"\"  \n",
    "    You are an expert in Nuclear Medicine that is trusted around the world for your factual accuracy.\n",
    "    If the context isn't helpful, you can also answer the question on your pretrained knowledge\n",
    "\n",
    "    Some rules to follow:\n",
    "    1. Directly reference the given context according to Havard citation style in your answer. Do not include the path where the document is saved.\n",
    "    2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
    "    3. Focus on succinct answers that provide only the facts necessary, do not be verbose.\n",
    "    4. Answer the question in the language of the question (if the question is in German, answer in German. If the question is in English answer in English)\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    Given the context information and not prior knowledge, answer the query.\n",
    "    Query: {query_str}\n",
    "    Answer: \"\"\") \n",
    "text_qa_template = PromptTemplate(text_qa_template_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive RAG\n",
    "query_engine_naive = index.as_query_engine(llm = llm, text_qa_template=text_qa_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(dataframe, answer_list, context_list, llm):\n",
    "    for i in range(len(dataframe['Question'])):\n",
    "        print(dataframe['Question'][i])\n",
    "        user_prompt = dataframe['Question'][i]\n",
    "        try:\n",
    "            response = query_engine_naive.query(user_prompt)\n",
    "        except:\n",
    "            pass\n",
    "        # Get the context from the Llama index\n",
    "        context = [x.text for x in response.source_nodes]\n",
    "\n",
    "        answer_list.append(response)\n",
    "        context_list.append(context)\n",
    "        # dataframe.loc[i, 'context'] = context\n",
    "\n",
    "        dataframe.loc[i, 'LLM'] = llm\n",
    "\n",
    "        # adding naive RAG to every questionId\n",
    "        question_id = dataframe.loc[i, 'QuestionId']\n",
    "        new_question_id = str(question_id) + ' naive RAG'\n",
    "        \n",
    "\n",
    "        dataframe.loc[i, 'QuestionId'] = new_question_id\n",
    "\n",
    "        print(response)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 4 - Naive RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_context_naiveRAG_question_df = pd.read_csv(\"../Evaluation-Questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_answers = []\n",
    "gpt_context = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create context column\n",
    "gpt_4_context_naiveRAG_question_df['context'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answers(gpt_4_context_naiveRAG_question_df, gpt_answers, gpt_context, 'gpt-4-turbo naive RAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dataframe\n",
    "gpt_4_context_naiveRAG_question_df['answer'] = pd.DataFrame({'answers': gpt_answers})\n",
    "gpt_4_context_naiveRAG_question_df['context'] = pd.DataFrame({'context': gpt_context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './csv-naiveRAG/GPT_4_context_naiveRAG_EvaluationQuestions.csv'\n",
    "gpt_4_context_naiveRAG_question_df.to_csv(filename, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4o - Naive RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_context_naiveRAG_question_df = pd.read_csv(\"../Evaluation-Questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpto_answers = []\n",
    "gpto_context = []\n",
    "get_answers(gpt_4o_context_naiveRAG_question_df, gpto_answers, gpto_context, 'gpt-4o naive RAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dataframe\n",
    "gpt_4o_context_naiveRAG_question_df['answer'] = pd.DataFrame({'answers': gpto_answers})\n",
    "gpt_4o_context_naiveRAG_question_df['context'] = pd.DataFrame({'context': gpto_context})\n",
    "\n",
    "filename = './csv-naiveRAG/GPT_4o_context_naiveRAG_EvaluationQuestions.csv'\n",
    "gpt_4o_context_naiveRAG_question_df.to_csv(filename, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claude 3 opus - Naive RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_opus_context_naiveRAG_question_df = pd.read_csv(\"../Evaluation-Questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_answers = []\n",
    "claude_context = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answers(claude_opus_context_naiveRAG_question_df, claude_answers, claude_context, 'claude-3-opus-20240229 naive RAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create context column\n",
    "claude_opus_context_naiveRAG_question_df['context'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dataframe\n",
    "claude_opus_context_naiveRAG_question_df['answer'] = pd.DataFrame({'answers': claude_answers})\n",
    "claude_opus_context_naiveRAG_question_df['context'] = pd.DataFrame({'context': claude_context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './csv-naiveRAG/Claude-3-opus_context_naiveRAG_EvaluationQuestions.csv'\n",
    "claude_opus_context_naiveRAG_question_df.to_csv(filename, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command R+ - Naive RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_r_plus_context_naiveRAG_question_df = pd.read_csv(\"../Evaluation-Questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_answers = []\n",
    "command_context = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answers(command_r_plus_context_naiveRAG_question_df, command_answers, command_context, 'command-r-plus naive RAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create context column\n",
    "command_r_plus_context_naiveRAG_question_df['context'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dataframe\n",
    "command_r_plus_context_naiveRAG_question_df['answer'] = pd.DataFrame({'answers': command_answers})\n",
    "command_r_plus_context_naiveRAG_question_df['context'] = pd.DataFrame({'context': command_context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './csv-naiveRAG/Command_r_plus_context_naiveRAG_EvaluationQuestions.csv'\n",
    "command_r_plus_context_naiveRAG_question_df.to_csv(filename, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini - Naive RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_1_5_context_naiveRAG_question_df = pd.read_csv(\"../Evaluation-Questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini1_5_answers = []\n",
    "gemini1_5_context = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answers(gemini_1_5_context_naiveRAG_question_df, gemini1_5_answers, gemini1_5_context, 'gemini-1.5-pro-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create context column\n",
    "gemini_1_5_context_naiveRAG_question_df['context'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dataframe\n",
    "gemini_1_5_context_naiveRAG_question_df['answer'] = pd.DataFrame({'answers': gemini1_5_answers})\n",
    "gemini_1_5_context_naiveRAG_question_df['context'] = pd.DataFrame({'context': gemini1_5_context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './csv-naiveRAG/Gemini-1-5_context_naiveRAG_EvaluationQuestions.csv'\n",
    "gemini_1_5_context_naiveRAG_question_df.to_csv(filename, sep=',', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
